### Ремарки

Преимущества последовательного анализа и Always valid p-values:
- И классический последовательный анализ Вальда и Always valid p-values позволяют "легально" подглядывать в тест. Можно не завязываться на продолжительность теста (можно пораньше остановить или наоборот подольше подержать).
- Просто интерпретируются. Можно перейти к p-values.
- Хорошо совместимы с поправками на множественную проверку гипотез.
- Действительно контролирует ошибку в пределах заданного уровня $\alpha$, при этом сокращая время проведения теста и во многих случаях почти не жертвуя мощностью.
Недостатки:
- Не очень хорошо работает на выборках неодинаковой мощности (то есть если группы разбиты НЕ 50/50). Кроме того может сильно шуметь выборочная дисперсия.
- Сильно зависит от способа вычисления $\tau$. 
- Данные должны быть из экспоненциального семейства. Для других распределений придется дорабатывать подход.
Общие замечания по последовательному анализу:
- Размер выборки не считается.
- Очень сложно спроектировать эксперимент, так как подход принимает данные порциями и сложно предсказать как будет распределяться эффект в этой новой порции данных.
### Полезные ссылки
- [Always Valid Inference: Continuous Monitoring of A/B Tests, Johari, Pekelis, Wall, 2019 ](https://arxiv.org/pdf/1512.04922)
- Последовательный анализ, Вальд А.
- [Choosing a Sequential Testing Framework. Comparisons and Discussions](https://engineering.atspotify.com/2023/03/choosing-sequential-testing-framework-comparisons-and-discussions/)
- [Anytime-Valid $F$-Tests for Faster Sequential Experimentation Through Covariate Adjustment](https://arxiv.org/pdf/2210.08589v1)
### Классический последовательный анализ Вальда

Есть нулевая гипотеза $H_0: \mu = 0$ (разность средних равна 0) и альтернативная $H_1: \mu = 0.1$ (разность средних неравна 0, но обязательно нужно задать какое-то $\mu$).

Строим логарифм правдоподобие (например, по нормальной модели) с известной дисперсией (выборочной) и параметрами $\mu$ из гипотез
$$
L(\mathbf{x} | \mu, \sigma^2) = - \dfrac{n}{2}\ln (2 \pi \sigma^2) - \dfrac{1}{2 \sigma^2} \sum_{i=1}^n (x_i - \mu)^2.
$$

Для дальнейшего сравнения будем рассматривать отношение функций правдоподобия для обеих гипотез
$$
\Lambda(X) = \dfrac{ L(0.1, \sigma^2) }{ L(0, \sigma^2) } = \dfrac{ \exp{\bigg(-\sum_{n=1}^n \dfrac{(x_i - 0.1)^2}{2\sigma^2}\bigg) }}{ \exp\bigg(- \sum_{i=1}^n \dfrac{x_i^2}{2 \sigma^2}\bigg) }
$$
И логарифм отношения
$$
\ln \Lambda(X) = \bigg( \sum_{i=1}^n \dfrac{X_i^2}{2 \sigma^2}\bigg) - \bigg( \sum_{i=1}^n \dfrac{(X_i - 0.1)^2}{2\sigma^2}\bigg)
$$
По мере роста размера выборки $\ln \Lambda(X)$ сравнивается со значениями $a = \log \dfrac{\beta}{1 - \alpha}$  и $b = \log\dfrac{1 - \beta}{\alpha}$ ,представляющие собой границы коридора, в котором колеблется $\ln \Lambda(X)$. 

Возможны следующие варианты:
- $\ln\Lambda(X) \geqslant b$ -- отклоняем нулевую гипотезу в пользу альтернативной, если кривая $\ln \Lambda(X)$ пересекает линию верхней границы $b$,
- $\ln \Lambda(X) \leqslant a$  -- принимаем нулевую гипотезу, если кривая $\ln \Lambda(X)$ пересекает линию нижней границы $a$.
- $\ln\Lambda(X) > a$  -- продолжаем тест.

Вальд и Вулфовиц доказали, что тест с этими границами является _наиболее мощным последовательным тестом_ отношения вероятностей.

### Альтернативный подход. Always valid p-values

Как и в случае классического последовательного анализа Вальда, у нас есть две гипотезы -- нулевая $H_0: \mu = 0$ (разность средних равна 0) и $H_1: \mu \neq 0$ (разность средних отличается от нуля, но мы ее не задаем).

По-прежнему используются функции правдоподобия, но теперь берется иное отношение, учитывающее смешанное распределение для $H_1$ (с учетом наблюдаемого выборочного среднего $s_n$ )
$$
\Lambda_n^H(s_n) = \int_\Theta \Bigg( \dfrac{f_\theta(s_n)}{f_{\theta_0}(s_n)} \Bigg)^n dH(\theta)
$$
В виде уравнения со всеми параметрами $\Lambda$ считается так
$$
\tilde{\Lambda}^{H, \theta_0} = \sqrt{ \dfrac{V_n}{V_n + n \, \tau^2} } \exp \Bigg( \dfrac{n^2 \, \tau^2 (\bar{Y}_n - \bar{X}_n - \theta_0)^2}{2 V_n (V_n + n \, \tau^2)} \Bigg),
$$
где $n$ -- накопленный размер выборки; $\bar{Y}_n$ и $\bar{X}_n$ -- средние для групп B и A, $V_n$ -- сумма выборочных дисперсий групп, $\tau$ -- дисперсия смешанного распределения (==может вычисляться по-разному!!!==).

$1 / \tilde{\Lambda}^{H, \theta_0}$ -- наблюдаемое p-value (если оно больше 1, то полученное значение усекают до 1, так как p-value это все-таки вероятность). То есть если, например, $\tilde{\Lambda}^{H, \theta_0} \approx 1$ , то $1 / \tilde{\Lambda}^{H, \theta_0}$ (p-value $\approx 1$) и потому у нас есть основания считать, что средние групп почти не различаются и нулевая гипотеза не отклониться.


